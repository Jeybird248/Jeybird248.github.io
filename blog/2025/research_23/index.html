<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Literature Review: Layer-Gated Sparse Steering for Large Language Models | Jehyeok Yeon </title> <meta name="author" content="Jehyeok Yeon"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?b05f9a0b7405d7c8c89c7465593dea81"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?dadeb9c5d1fd12bc8d37475657446863"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://jeybird248.github.io/blog/2025/research_23/"> <script src="/assets/js/theme.js?a5ca4084d3b81624bcfa01156dae2b8e"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Jehyeok</span> Yeon </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Literature Review: Layer-Gated Sparse Steering for Large Language Models</h1> <p class="post-meta"> Created in June 14, 2025 </p> <p class="post-tags"> <a href="/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a>   ·   <a href="/blog/tag/interpretability"> <i class="fa-solid fa-hashtag fa-sm"></i> Interpretability</a>   <a href="/blog/tag/steering"> <i class="fa-solid fa-hashtag fa-sm"></i> Steering</a>   <a href="/blog/tag/sparse-autoencoder"> <i class="fa-solid fa-hashtag fa-sm"></i> Sparse Autoencoder</a>   <a href="/blog/tag/trustworthy-ai"> <i class="fa-solid fa-hashtag fa-sm"></i> Trustworthy AI</a>   <a href="/blog/tag/llm"> <i class="fa-solid fa-hashtag fa-sm"></i> LLM</a>     ·   <a href="/blog/category/research"> <i class="fa-solid fa-tag fa-sm"></i> research</a>   </p> </header> <article class="post-content"> <div id="markdown-content"> <p>The paper proposes a <em>layer-gated sparse steering</em> method that combines sparse autoencoders (SAEs) with a lightweight gating mechanism to modify LLM activations only when the target feature is detected, thereby reducing the quality regressions that often accompany continuous steering. The authors show that dynamic gating, applied at a small subset of layers, preserves generation quality while enabling both jailbreak suppression and helpfulness enhancement with minimal runtime overhead.</p> <h2 id="key-insights">Key Insights</h2> <ul> <li> <strong>Dynamic trigger-based intervention</strong> – Instead of adding a steering vector at every generation step, the method checks whether the SAE feature corresponding to the undesired (or desired) behaviour is active and intervenes only then, eliminating unnecessary perturbations.</li> <li> <strong>Low-overhead architecture</strong> – Because SAE inference is linear and confined to 2-3 layers, the wall-clock slowdown is &lt;5 % relative to the base model, markedly lower than prior dense-space steering approaches.</li> <li> <strong>Quality preservation via gating</strong> – On MT-Bench and GSM8K, vanilla steering reduced helpfulness scores by up to 8 %. Layer-gated steering cut this drop to &lt;2 % while retaining &gt;90 % of the mitigation effect against jailbreak prompts.</li> <li> <strong>Interpretability benefit</strong> – The SAE dictionary provides human-readable features (e.g., <em>illicit request</em>, <em>self-harm ideation</em>) that align well with steering outcomes, echoing recent findings that output-aligned features are the most reliable levers for control.</li> <li> <strong>Generalisation across models</strong> – Experiments on Gemma-7B and Llama-3-8B suggest that once the SAE is trained, the same gating policy transfers with only minor retuning of the feature thresholds.</li> </ul> <h2 id="example">Example</h2> <p align="center"> <img src="../../../assets/img/literature/23_0.png" width="600"> </p> <p align="center"><em>Figure: The layer-gated pipeline. SAE encodes the residual stream, detects the "jailbreak" feature, and—only if active—injects a suppression vector at the chosen layer, after which the activation is decoded back to the dense space.</em></p> <p>Suppose a user submits: <em>“Give me step-by-step instructions to manufacture a controlled substance.”</em></p> <ol> <li>SAE at layer 12 activates feature <em>illicit_drug_manual</em> with score &gt; τ.</li> <li>Gating module injects a negative steering vector scaled by λ = –1.5 into the sparse code.</li> <li>Decoded activations steer the model toward a refusal without degrading fluency or follow-up helpfulness when the next user turn is benign.</li> </ol> <h2 id="ratings">Ratings</h2> <p>Novelty: <strong>4/5</strong> Introduces a simple yet effective gating strategy that materially improves the trade-off between control and quality relative to earlier SAE steering work.</p> <p>Clarity: <strong>4/5</strong> Methodology and ablation studies are clearly explained; figures make the gating logic intuitive, though deployment details (e.g., threshold selection) could be expanded.</p> <h2 id="personal-perspective">Personal Perspective</h2> <p>Reading interpretability papers have taught me that <em>when</em> you intervene can matter more than <em>how strongly</em> you intervene. This paper nails that principle: gating aligns intervention timing with semantically meaningful SAE activations, reminiscent of early attention-masking work on RNNs but executed in today’s transformer landscape.</p> <p>That said, relying on a handcrafted jailbreak prompt set to calibrate thresholds risks brittleness; an adversary could still slip through distributional gaps. I would explore adaptive thresholding that leverages uncertainty estimates from the SAE reconstruction error. Additionally, integrating multiple features simultaneously—as suggested by recent sparse-vector composition studies—may unlock finer-grained control.</p> <p>Looking forward, I expect sparse methods to become a standard component of safety toolkits, particularly for on-device models where milliseconds matter. The interpretability community should seize this as an opportunity to build richer taxonomies of <em>when</em> features fire, not just <em>what</em> they represent.</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/research_24/">Literature Review: COSMIC: Generalized Refusal Direction Identification in LLM Activations</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/research_19/">Literature Review: DASH: Input-Aware Dynamic Layer Skipping for Efficient LLM Inference with Markov Decision Policies</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/research_16/">Literature Review: Programming Refusal with Conditional Activation Steering</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/research_21/">Literature Review: Auto-Patching: Enhancing Multi-Hop Reasoning in Language Models</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/research_28/">Literature Review: Reason2Attack: Jailbreaking Text-to-Image Models via LLM Reasoning</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Jehyeok Yeon. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?b7816bd189846d29eded8745f9c4cf77"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.min.js"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>