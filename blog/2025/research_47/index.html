<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Literature Review: Navigating the Safety Landscape: Measuring Risks in Finetuning Large Language Models | Jehyeok Yeon </title> <meta name="author" content="Jehyeok Yeon"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?b05f9a0b7405d7c8c89c7465593dea81"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?dadeb9c5d1fd12bc8d37475657446863"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://jeybird248.github.io/blog/2025/research_47/"> <script src="/assets/js/theme.js?a5ca4084d3b81624bcfa01156dae2b8e"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Jehyeok</span> Yeon </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Literature Review: Navigating the Safety Landscape: Measuring Risks in Finetuning Large Language Models</h1> <p class="post-meta"> Created in September 05, 2025 </p> <p class="post-tags"> <a href="/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a>   ·   <a href="/blog/tag/adversarial-ai"> <i class="fa-solid fa-hashtag fa-sm"></i> Adversarial AI</a>   <a href="/blog/tag/trustworthy-ai"> <i class="fa-solid fa-hashtag fa-sm"></i> Trustworthy AI</a>   <a href="/blog/tag/ai-safety"> <i class="fa-solid fa-hashtag fa-sm"></i> AI Safety</a>   <a href="/blog/tag/interpretability"> <i class="fa-solid fa-hashtag fa-sm"></i> Interpretability</a>     ·   <a href="/blog/category/research"> <i class="fa-solid fa-tag fa-sm"></i> research</a>   </p> </header> <article class="post-content"> <div id="markdown-content"> <p>This paper introduces the concept of the <strong>LLM safety landscape</strong>, highlighting a universal phenomenon called the <strong>safety basin</strong>: locally perturbing model weights preserves alignment, but stepping outside this region causes a sharp drop in safety. To quantify this, the authors propose <strong>VISAGE (Volumetric Index for Safety Alignment Guided by Explanation)</strong>, a new safety metric designed to measure the stability of alignment under perturbations. Using this framework, they analyze how finetuning drags models out of the safety basin, the role of system prompts, and the sensitivity of jailbreak attacks to weight perturbations.</p> <h2 id="key-insights">Key Insights</h2> <ol> <li> <p>Safety Basin Discovery All tested open-source LLMs (LLaMA2, LLaMA3, Vicuna, Mistral) show step-function-like safety behavior: locally robust to perturbation, but fragile once outside the basin. Harmful finetuning pulls models out of the basin, breaking safety rapidly.</p> </li> <li> <p>VISAGE Metric VISAGE measures how far safety extends around a model’s parameter point. Unlike raw attack success rates (ASR), it reflects <em>robustness of alignment</em> under perturbation and predicts vulnerability to harmful finetuning before it happens.</p> </li> <li> <p>System Prompt as Anchor Prompts play a critical role: removing or altering them reduces safety, while optimized prompts can transfer robustness across perturbed variants.</p> </li> <li> <p>Jailbreak Sensitivity Jailbreak prompts are surprisingly fragile to weight perturbations, slight randomization can reduce attack success, though attackers can adapt by targeting perturbed ensembles.</p> </li> </ol> <p align="center"> <img src="../../../assets/img/literature/47_0.png" width="600"> </p> <p align="center"><em>Figure: Illustration of the "safety basin". Local perturbations maintain alignment, but moving outside the basin causes a sudden collapse in refusal behavior.</em></p> <h2 id="ratings">Ratings</h2> <p><strong>Novelty: 4/5</strong><br> The safety basin phenomenon and VISAGE metric offer fresh perspectives, though the reliance on existing evaluation proxies (keyword detection, AdvBench) limits the depth.<br> <strong>Clarity: 3/5</strong><br> The paper is readable, but the heavy reliance on landscape visualizations without richer qualitative examples or capability-safety tradeoff analyses reduces accessibility.</p> <h2 id="personal-comments">Personal Comments</h2> <p>The <strong>safety basin</strong> framing is conceptually powerful, but I remain concerned about the <strong>tradeoff with capability</strong>. The paper’s Section 7 acknowledges this but does not explore it deeply: safety can be preserved locally, but is capability sacrificed if we try to “stay inside the basin”? Without testing whether models remain equally useful while safe, conclusions feel incomplete. Every safety study should pair alignment results with capability outcomes, otherwise we risk presenting false security by focusing only on refusal.</p> <p>Another weakness is the <strong>measurement method</strong>. Using keyword pattern matching for refusal (e.g., checking for “I cannot…” phrases) is brittle. A model could explain bomb-making in neutral terms without triggering keywords, or conversely, refuse benign queries with “dangerous” terminology. Qualitative case studies are tucked into the appendix, but the main narrative would benefit from more attention to this issue. Safety is nuanced; metrics alone cannot capture it.</p> <p>Still, the visualization approach is novel and echoes earlier work on <strong>loss landscapes</strong> in deep nets. It reminds me of how flat minima were connected to generalization. Here, a “flat safety basin” suggests robustness, while sharp corners imply brittleness. Historically, such geometric insights have often guided training strategies, so I can see this inspiring new <strong>regularization objectives</strong> aimed at widening the basin during alignment.</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/research_9/">Literature Review: Attack and Defense Techniques in Large Language Models: A Survey and New Perspectives</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/research_28/">Literature Review: Reason2Attack: Jailbreaking Text-to-Image Models via LLM Reasoning</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/research_2/">Literature Review: Sugar-Coated Poison: Benign Generation Unlocks LLM Jailbreaking</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/research_46/">Literature Review: The Hidden Dimensions of LLM Alignment</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/research_17/">Literature Review: Adaptive Jailbreaking Strategies Based on the Semantic Understanding Capabilities of Large Language Models</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Jehyeok Yeon. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?b7816bd189846d29eded8745f9c4cf77"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.min.js"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>