<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Literature Review: Auto-Patching: Enhancing Multi-Hop Reasoning in Language Models | Jehyeok Yeon </title> <meta name="author" content="Jehyeok Yeon"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?b05f9a0b7405d7c8c89c7465593dea81"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?dadeb9c5d1fd12bc8d37475657446863"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://jeybird248.github.io/blog/2025/research_21/"> <script src="/assets/js/theme.js?a5ca4084d3b81624bcfa01156dae2b8e"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Jehyeok</span> Yeon </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Literature Review: Auto-Patching: Enhancing Multi-Hop Reasoning in Language Models</h1> <p class="post-meta"> Created in June 14, 2025 </p> <p class="post-tags"> <a href="/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a>   ·   <a href="/blog/tag/llm"> <i class="fa-solid fa-hashtag fa-sm"></i> LLM</a>   <a href="/blog/tag/reasoning"> <i class="fa-solid fa-hashtag fa-sm"></i> Reasoning</a>   <a href="/blog/tag/interpretability"> <i class="fa-solid fa-hashtag fa-sm"></i> Interpretability</a>   <a href="/blog/tag/mechanistic-interpretability"> <i class="fa-solid fa-hashtag fa-sm"></i> Mechanistic Interpretability</a>     ·   <a href="/blog/category/research"> <i class="fa-solid fa-tag fa-sm"></i> research</a>   </p> </header> <article class="post-content"> <div id="markdown-content"> <p>This paper introduces “Auto-Patch,” a method designed to improve the multi-hop reasoning capabilities of Large Language Models (LLMs). Building directly upon the <code class="language-plaintext highlighter-rouge">PatchScopes</code> framework, the authors automate the process of “patching” or replacing hidden states during inference. The core contribution is the use of a trained classifier (an SVM) to dynamically decide which token representations should be copied from an earlier layer to a later one, aiming to correct reasoning failures. Evaluated on the MuSiQue 2-hop question-answering dataset, Auto-Patch improves the LLaMA 2 (7B) model’s solve rate from a baseline of 18.45% to 23.63%, closing some of the gap to standard Chain-of-Thought (CoT) prompting, which achieves 27.44%.</p> <h3 id="key-insights">Key Insights</h3> <p>The central idea of this work is to transition model editing from a manual, exploratory practice to a learned, automated one. The original <code class="language-plaintext highlighter-rouge">PatchScopes</code> paper provided a powerful tool for interpretability research, but its reliance on manual intervention limited its practical application. Auto-Patch proposes a solution by framing the intervention decision as a supervised learning problem.</p> <p>The methodology for training the classifier is straightforward:</p> <ol> <li>For a given question, perform a brute-force patch for each token position, copying the hidden state from a source layer (i.e., layer 15) to a target layer (i.e., layer 8).</li> <li>Evaluate if the patch improved the model’s likelihood of generating the correct answer.</li> <li>Label the hidden state vector as <code class="language-plaintext highlighter-rouge">True</code> (patch is beneficial) or <code class="language-plaintext highlighter-rouge">False</code> (patch is not).</li> <li>Train a binary classifier on this generated dataset of hidden states and their corresponding labels.</li> </ol> <p>During inference, the model performs a first forward pass to generate hidden states, which are fed to the classifier. A second forward pass is then executed, applying the patches as predicted by the classifier.</p> <p>The paper’s analysis reveals that the classifier learns a simple but interesting heuristic. It mostly learns <em>not</em> to patch structural or non-content tokens, such as the start-of-sentence symbol <code class="language-plaintext highlighter-rouge">&lt;s&gt;</code>, unknown tokens <code class="language-plaintext highlighter-rouge">&lt;unk&gt;</code>, or punctuation like <code class="language-plaintext highlighter-rouge">.</code>. This implies that for the vast majority of content-bearing tokens, the intervention is deemed beneficial. This suggests the information present at the mid-to-late layers (like layer 15) is generally more useful for the final output than the representations at an earlier intermediate layer (like layer 8) for this specific task.</p> <p>Furthermore, experiments exploring different source and target layer combinations confirm the well-established principle that different layers in a transformer have specialized roles. Performance peaks when patching from mid-level layers (around 10-12), which are thought to capture more abstract semantic relationships, as opposed to early layers (focused on syntax) or late layers (over-specialized for next-token prediction).</p> <h3 id="example">Example</h3> <p>The Auto-Patch framework is designed to intervene during inference to improve reasoning. Consider a 2-hop question from the MuSiQue dataset: <em>“What award was received by the person who authored Missing Person?”</em></p> <p>The process would be as follows:</p> <ol> <li> <strong>First Pass:</strong> The model processes the input question in a standard forward pass.</li> <li> <strong>Classification:</strong> At layer 15, the hidden state for each token is extracted and passed to the trained SVM classifier. The classifier predicts whether patching this state into layer 8 would be beneficial.</li> <li> <strong>Patching Decision:</strong> The classifier might predict <code class="language-plaintext highlighter-rouge">True</code> for most content tokens (“award,” “received,” “person,” “authored,” “Missing,” “Person”) but <code class="language-plaintext highlighter-rouge">False</code> for the <code class="language-plaintext highlighter-rouge">&lt;s&gt;</code> token.</li> <li> <strong>Second Pass:</strong> A second forward pass is initiated. When the computation reaches layer 8, the original hidden states for the tokens marked <code class="language-plaintext highlighter-rouge">True</code> are replaced with their corresponding hidden states from layer 15.</li> <li> <strong>Final Generation:</strong> The model continues the forward pass from layer 8 with the patched representations, which ideally provides it with the necessary information linkage to connect “Missing Person” to its author, and then that author to the award they received, thus generating the correct final answer.</li> </ol> <p align="center"> <img src="../../../assets/img/literature/21_0.png" width="700"> </p> <p align="center"><em>Figure: An illustration of the Auto-Patch framework. A classifier determines whether a hidden state from a source layer should be patched into a target layer to improve the model's reasoning process.</em></p> <h3 id="ratings">Ratings</h3> <p><strong>Novelty: 2/5</strong></p> <p>The work is a logical and incremental extension of the <code class="language-plaintext highlighter-rouge">PatchScopes</code> paper. Automating a manual process with a standard classifier is a useful engineering step but does not introduce a fundamentally new concept or capability. The core ideas of model editing via patching belong to prior work.</p> <p><strong>Clarity: 3/5</strong> The paper is well-structured and clearly written. The methodology, experimental setup, and results are presented in a way that is easy to follow. The authors do a good job of explaining what they did and how they did it.</p> <h3 id="personal-comments">Personal Comments</h3> <p>This paper is an interesting proof-of-concept that successfully automates the intervention strategy proposed by <code class="language-plaintext highlighter-rouge">PatchScopes</code>. However, its contributions feel preliminary and raise more questions than they answer.</p> <p>My primary concern is the lack of a deep, mechanistic explanation for <em>why</em> the method works. The classifier is treated as a black box trained on empirical outcomes. While the analysis of which tokens are <em>not</em> patched provides a clue, it doesn’t reveal what specific information is being corrected or inserted by the patch. Is an entity representation being updated? Is a faulty relational computation being bypassed? The work demonstrates <em>that</em> a patch from layer 15 to layer 8 helps, but it fails to provide the satisfying <em>how</em> or <em>why</em>. This approach feels less like reverse-engineering a model’s reasoning circuit and more like applying a brute-force fix.</p> <p>The second major issue is the practical justification. Auto-Patch improves over the baseline but is still significantly outperformed by standard Chain-of-Thought (CoT) prompting. The paper is silent on the critical trade-offs of this approach. Auto-Patch requires two full forward passes plus the overhead of a classifier, which is computationally expensive. For this method to be compelling, it would need to offer a significant advantage over CoT, such as much lower latency or generation cost. Without a thorough analysis of runtime, token count, and overall compute, it is difficult to see a scenario where one would choose this method over the existing, higher-performing alternative.</p> <p>This work reminds me of early attempts at model steering, where we would try to nudge model behavior through targeted interventions. The automation aspect is a modern touch, but the core challenge remains: making these interventions both effective and efficient. To move this work forward, I would have explored more interpretable classifiers (i.e., sparse linear models) to understand the features within the hidden state that trigger a patch. This might have provided the mechanistic insight that is currently missing. Ultimately, for this line of research to be impactful, it must either beat state-of-the-art methods on a key metric or provide novel insights into the inner workings of these complex models. As it stands, this paper doesn’t quite achieve either.</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/research_19/">Literature Review: DASH: Input-Aware Dynamic Layer Skipping for Efficient LLM Inference with Markov Decision Policies</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/research_17/">Literature Review: Adaptive Jailbreaking Strategies Based on the Semantic Understanding Capabilities of Large Language Models</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/research_32/">Literature Review: A Survey on Latent Reasoning</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/research_13/">Literature Review: Enhancing Latent Computation in Transformers with Latent Tokens</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/research_9/">Literature Review: Attack and Defense Techniques in Large Language Models: A Survey and New Perspectives</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Jehyeok Yeon. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?b7816bd189846d29eded8745f9c4cf77"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.min.js"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>