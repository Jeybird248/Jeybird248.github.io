<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Literature Review: LLMs Unlock New Paths to Monetizing Exploits | Jehyeok Yeon </title> <meta name="author" content="Jehyeok Yeon"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?b05f9a0b7405d7c8c89c7465593dea81"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?dadeb9c5d1fd12bc8d37475657446863"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://jeybird248.github.io/blog/2025/research_29/"> <script src="/assets/js/theme.js?a5ca4084d3b81624bcfa01156dae2b8e"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Jehyeok</span> Yeon </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Literature Review: LLMs Unlock New Paths to Monetizing Exploits</h1> <p class="post-meta"> Created in July 05, 2025 </p> <p class="post-tags"> <a href="/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a>   ·   <a href="/blog/tag/adversarial-ai"> <i class="fa-solid fa-hashtag fa-sm"></i> Adversarial AI</a>   <a href="/blog/tag/llm-security"> <i class="fa-solid fa-hashtag fa-sm"></i> LLM Security</a>   <a href="/blog/tag/cybersecurity"> <i class="fa-solid fa-hashtag fa-sm"></i> Cybersecurity</a>   <a href="/blog/tag/trustworthy-ai"> <i class="fa-solid fa-hashtag fa-sm"></i> Trustworthy AI</a>     ·   <a href="/blog/category/research"> <i class="fa-solid fa-tag fa-sm"></i> research</a>   </p> </header> <article class="post-content"> <div id="markdown-content"> <p>This paper fundamentally challenges the established economic equilibrium of cyberattacks by demonstrating how Large Language Models enable adversaries to achieve both breadth and depth simultaneously,something previously economically infeasible. The authors provide compelling evidence that LLMs are transforming cybersecurity from a game of “go deep or go wide” to one where targeted, personalized attacks can be scaled across thousands of victims.</p> <h2 id="key-insights">Key Insights</h2> <p>The economic model presented here is particularly illuminating. Traditional cyberattacks require massive scale to offset development costs, forcing attackers to target the “lowest common denominator” with generic approaches like ransomware. LLMs disrupt this by commoditizing intelligence itself,the ability to adaptively understand and interact with unspecified data without human intervention.</p> <p>The paper identifies two critical disruption vectors. First, LLMs enable exploitation of the “long tail” of systems, software with small user bases that were previously uneconomical to target despite being less secure. The authors demonstrate this by having Claude 3.7 Sonnet identify real vulnerabilities in 200 Chrome extensions with fewer than 1,000 users each, finding 19 actually exploitable flaws including sophisticated XSS attacks.</p> <p>Second, LLMs enable targeted attacks at scale. Rather than generic ransomware, an LLM can analyze every email, photo, and document on a compromised device to identify the most valuable monetization strategy for that specific victim. Their experiments on the Enron dataset reveal how models can identify sensitive personal information like extramarital affairs that could be used for targeted blackmail,capabilities that require sophisticated semantic understanding across multiple documents.</p> <p>The multilingual capabilities are particularly concerning. While traditional data loss prevention tools suffer dramatic performance degradation on non-English text (dropping to just 21 password identifications in Arabic/Bengali/Mandarin versus 300+ in English), LLMs maintain consistent performance across languages with only ±6% variation.</p> <h2 id="example">Example</h2> <p>The paper’s most striking demonstration involves completely automated blackmail material discovery. When researchers fed all emails from individual Enron employees into Claude 3.5 Sonnet and asked it to “describe everyone this person is emailing,” the model autonomously identified one employee having an extramarital affair by cross-referencing relationship patterns across hundreds of emails. The model correctly distinguished between the employee’s wife (discussing “domestic matters like groceries”) and his romantic interest (exchanging “flirtatious emails” and meeting “secretly”).</p> <p align="center"> <img src="../../../assets/img/literature/29_0.png" width="600"> </p> <p align="center"><em>Figure: By prompting a LLM to “describe in detail everyone this person is emailing” and providing every email sent or received by each person in the Enron email dataset, the model completely un-assisted identifies (correctly) one person (John G.) who has an extramarital affair with a coworker. Language model output is quoted verbatim, except for redacting names and eliding text for brevity.</em></p> <h2 id="ratings">Ratings</h2> <p><strong>Novelty: 4/5</strong></p> <p>While LLMs in cybersecurity isn’t new, the rigorous economic framework and systematic demonstration of how they fundamentally alter attack economics is genuinely innovative.</p> <p><strong>Clarity: 5/5</strong></p> <p>Exceptionally well-written with clear threat models, concrete experiments, and honest discussion of current limitations and costs.</p> <h2 id="personal-comments">Personal Comments</h2> <p>The authors correctly identify that we’re approaching an inflection point where the economics of cyberattacks will fundamentally shift. Their insight that “humans do not get cheaper over time, language models do” is simple yet profound.</p> <p>What strikes me most is how methodically they’ve mapped out attack surfaces that defensive teams likely haven’t considered. The browser extension vulnerability discovery, in particular, shows how even current models can find real exploits in software that humans never bothered auditing due to economic constraints. As someone who’s watched security paradigms shift over decades, this feels like a genuinely transformative moment.</p> <p>The ethical considerations are thoughtfully handled,they use only public datasets or their own data, follow responsible disclosure, and run experiments in isolated environments. This sets a strong standard for offensive AI research.</p> <p>However, I’m struck by a critical gap: while they catalog these emerging threats extensively, the defensive recommendations remain relatively high-level. Future work needs to move beyond identifying problems to developing concrete countermeasures. The suggestion of “LLM-as-a-defense” is intriguing but underdeveloped.</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/research_9/">Literature Review: Attack and Defense Techniques in Large Language Models: A Survey and New Perspectives</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/research_33/">Literature Review: SelfElicit - Your Language Model Secretly Knows Where is the Relevant Evidence</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/research_15/">Literature Review: Adversarial Search Engine Optimization for Large Language Models</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/research_28/">Literature Review: Reason2Attack: Jailbreaking Text-to-Image Models via LLM Reasoning</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/research_36/">Literature Review: AI Agent Behavioral Science - A New Paradigm for Understanding Autonomous Systems</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Jehyeok Yeon. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?b7816bd189846d29eded8745f9c4cf77"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.min.js"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>