<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Literature Review: AI Research Agents for Machine Learning: Search, Exploration, and Generalization in MLE-bench | Jehyeok Yeon </title> <meta name="author" content="Jehyeok Yeon"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?b05f9a0b7405d7c8c89c7465593dea81"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?dadeb9c5d1fd12bc8d37475657446863"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://jeybird248.github.io/blog/2025/research_34/"> <script src="/assets/js/theme.js?a5ca4084d3b81624bcfa01156dae2b8e"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Jehyeok</span> Yeon </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Literature Review: AI Research Agents for Machine Learning: Search, Exploration, and Generalization in MLE-bench</h1> <p class="post-meta"> Created in July 19, 2025 </p> <p class="post-tags"> <a href="/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a>   ·   <a href="/blog/tag/agentic-ai"> <i class="fa-solid fa-hashtag fa-sm"></i> Agentic AI</a>   <a href="/blog/tag/llm"> <i class="fa-solid fa-hashtag fa-sm"></i> LLM</a>   <a href="/blog/tag/automation"> <i class="fa-solid fa-hashtag fa-sm"></i> Automation</a>     ·   <a href="/blog/category/research"> <i class="fa-solid fa-tag fa-sm"></i> research</a>   </p> </header> <article class="post-content"> <div id="markdown-content"> <p>This paper introduces a framework for AI research agents that automate machine learning tasks by treating them as search problems over code artifacts. It formalizes agents as combinations of search policies and operators, evaluates them on the MLE-bench benchmark (a set of Kaggle competitions), and achieves a state-of-the-art medal rate of 47.7% on the lite version by improving operators and pairing them with strategies like greedy search, MCTS, and evolutionary algorithms. The work highlights bottlenecks in operator design, the impact of generalization gaps, and the need for robust evaluation, while developing the AIRA-dojo framework for scalable experimentation.</p> <h2 id="key-insights">Key Insights</h2> <p>The paper frames AI research agents as graph-based search algorithms navigating a space of code artifacts, where nodes represent partial solutions (i.e. Python scripts for ML models) and edges denote transformations via operators like Draft, Debug, Improve, Memory, and Crossover. This decomposition separates search policies—which balance exploration and exploitation—from operators that generate or refine artifacts, allowing systematic ablation studies. For instance, the authors show that AIDE’s original operators bottleneck performance, with advanced search like MCTS yielding no gains until operators are improved (i.e. via prompt-adaptive complexity and scoped memory).</p> <p>A core finding is the generalization gap: agents optimize on validation scores but are evaluated on held-out test sets, leading to overfitting where test performance plateaus or declines despite validation improvements. Selecting final solutions by test score (an oracle baseline) boosts medal rates by 9-13%, emphasizing the need for strategies like multiple submissions to mitigate noise. The work also underscores environmental factors, with AIRA-dojo enabling a 30% relative improvement over prior baselines by providing isolated, scalable compute.</p> <p>Implications for the field include the potential for agents to automate ML engineering, but with caveats: high compute demands limit scalability, and issues like bug fixation loops or mode collapse in operators hinder reliability. Future directions might involve agentic operators (i.e. nested agents for ideation) or fine-tuning LLMs for better robustness, while addressing data contamination in benchmarks.</p> <h2 id="example">Example</h2> <p>Consider a Kaggle competition for image classification. An initial node might contain code for a simple CNN with basic data loading. Applying the Improve operator could generate a child node that adds data augmentation and fine-tunes a pre-trained ResNet model, evaluated via 5-fold cross-validation. In an evolutionary policy, two such nodes might be crossed over to combine features (i.e. one parent’s augmentation with another’s architecture), producing offspring evaluated for fitness. This iterative process builds a search graph, with MCTS exploring uncertain branches to avoid local optima.</p> <h2 id="ratings">Ratings</h2> <p><strong>Novelty: 4/5</strong></p> <p>This work advances agent design by disentangling search components and demonstrating operator bottlenecks, offering a fresh perspective on scaling automated ML, though it builds on existing tree-search paradigms without revolutionary algorithmic innovations.</p> <p><strong>Clarity: 3/5</strong></p> <p>The exposition is functional but assumes familiarity with their previous works; more preliminary explanations of the search graph setup and node representations would improve accessibility, as the dense technical details can obscure the overall framework.</p> <h2 id="personal-comments">Personal Comments</h2> <p>This paper seems to agree with the ongoing push toward democratizing AI development, much like how NAS techniques in the 2010s aimed to reduce expertise barriers. It makes sense in light of existing services like Lovable and Cursor, which already iterate on code via tool calling to build apps, suggesting a natural extension to ML pipelines. That said, I found the tree structure explanation somewhat opaque; nodes aren’t just hyperparameters but encompass full code for feature engineering, model architecture, and more—i.e., one node might use logistic regression with basic features, while a child adds polynomial features. The search policies help navigate without getting stuck, which is a solid contribution.</p> <p>What concerns me is the heavy compute reliance and tendencies to overfit or loop on bugs, reminiscent of early genetic algorithms’ inefficiencies that plagued optimization in the 1990s. These agents are promising but imperfect, potentially needing better planning mechanisms or LLM fine-tuning to enhance robustness. This could mark the start of another revolution, automating entry-level data science roles, for better or worse. I’d approach differently by integrating human-in-the-loop feedback earlier to curb overfitting, and it raises questions about ethical implications: if agents replace junior roles, how do we ensure diverse entry points into the field? Overall, this fits into the broader landscape of agentic AI, pushing toward fully autonomous research but highlighting persistent challenges in generalization and efficiency that have dogged the field for decades.</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/research_21/">Literature Review: Auto-Patching: Enhancing Multi-Hop Reasoning in Language Models</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/research_20/">Literature Review: Thinkless: LLM Learns When to Think</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/research_7/">Literature Review: Exploring the Role of Large Language Models in Cybersecurity: A Systematic Survey</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/research_27/">Literature Review: RedCode: Risky Code Execution and Generation Benchmark for Code Agents</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/research_18/">Literature Review: Gaming Tool Preferences in Agentic LLMs</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Jehyeok Yeon. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?b7816bd189846d29eded8745f9c4cf77"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.min.js"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>